\section{Configurazione Sperimentale}

In questo capitolo viene descritta la metodologia seguita per la configurazione del sistema di acquisizione e la successiva pipeline di elaborazione dei dati. Il raggiungimento di una misura affidabile dell'indice NDVI richiede non solo la scelta di sensori appropriati, ma anche una rigorosa coerenza spaziale e radiometrica tra le diverse bande spettrali acquisite. Verranno quindi analizzati i principi teorici dell'indice di vegetazione, l'architettura fisica del setup sperimentale progettato per garantire stabilità meccanica e le fasi cruciali del processo di calibrazione e allineamento stereo, necessarie per trasformare dati grezzi provenienti da sensori eterogenei in mappe multispettrali allineate pixel-per-pixel.

\subsection{Indice NDVI}

Gli indici di vegetazione costituiscono uno strumento essenziale nel telerilevamento per monitorare da remoto lo stato fisiologico della biomassa vegetale. L'indice più accreditato in letteratura scientifica è il Normalized Difference Vegetation Index (NDVI). Questo indicatore sfrutta la differenza spettrale tra la riflettanza della radiazione nel vicino infrarosso (NIR) e quella nel rosso visibile (Red).

La relazione matematica che definisce l'indice è espressa dalla formula:

$$
\mathrm{NDVI} = \frac{\mathrm{NIR} - \mathrm{Red}}{\mathrm{NIR} + \mathrm{Red}}
$$

Il principio di funzionamento si basa sulla fisiologia vegetale: durante la fotosintesi, la clorofilla assorbe gran parte della radiazione rossa, mentre la struttura fogliare riflette intensamente la radiazione infrarossa. Tuttavia, in presenza di stress idrico, carenze nutrizionali o patologie, questo comportamento si inverte: la pianta assorbe meno luce rossa a causa della ridotta attività fotosintetica e riflette meno infrarosso per il deterioramento cellulare. Analizzando il rapporto tra queste due bande è quindi possibile diagnosticare rapidamente la salute della coltura. L'indice restituisce valori normalizzati in un intervallo compreso tra -1 e 1: valori tendenti a 1 indicano una vegetazione vigorosa e densa; valori prossimi a 0 segnalano vegetazione sofferente; valori negativi indicano assenza di biomassa (suolo nudo, strutture artificiali).

\subsection{Setup di Acquisizione}

Poiché l'NDVI è calcolato tramite un operatore puntuale a livello di pixel, ovvero una funzione che elabora ogni singolo pixel indipendentemente dai suoi vicini, il confronto diretto tra le mappe ottenute dalla Mapir Survey 3 e dalla Intel RealSense D435i richiede che ogni pixel dell'immagine sorgente corrisponda esattamente allo stesso punto fisico nell'immagine di destinazione. Dato che i due sensori possiedono ottiche, risoluzioni e posizioni spaziali differenti, è necessario risolvere il problema della corrispondenza geometrica, noto in letteratura come \emph{Dense Stereo Matching}.

Per affrontare questa problematica esistono due approcci metodologici principali. La prima via consiste nell'utilizzo di algoritmi classici di computer vision, che prevedono una pipeline geometrica strutturata in fasi di calibrazione delle camere, rettifica delle immagini, calcolo delle mappe di disparità e allineamento stereo. La seconda via prevede l'impiego di metodi basati su deep learning, che tuttavia richiedono hardware dedicato ad alte prestazioni (GPU) e modelli pre-addestrati su vasti dataset stereoscopici, spesso non disponibili per configurazioni custom come quella in esame.

In questo progetto si è deciso di adottare la pipeline classica, procedendo dalla calibrazione intrinseca ed estrinseca dei sensori fino alla rettifica epipolare e al successivo allineamento dei flussi video. Per garantire la stabilità necessaria a tali elaborazioni geometriche, è stato fondamentale eliminare ogni vibrazione o movimento relativo tra i sensori. Pertanto, le due camere sono state montate rigidamente su un profilo metallico estruso, mantenendo una baseline fissa, e il tutto è stato posizionato su un treppiede statico. Per assicurare il corretto posizionamento, sono stati progettati e realizzati supporti su misura.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\textwidth]{ch-configurazione-sperimentale/images/realsense.png}
	\caption{RealSense D435i (sinistra); Modulo di fissaggio (destra)}
	\label{fig:realsense-cad}
\end{figure}

La fig. \ref{fig:realsense-cad} mostra il modello CAD per il fissaggio della Intel RealSense D435i.

\subsection{Calibrazione del Sistema Stereo}

L'integrazione di due dispositivi di acquisizione distinti pone un problema geometrico noto come corrispondenza stereo. Poiché i due sensori sono fisicamente dislocati in posizioni differenti, dotati di ottiche con caratteristiche diverse e osservano la scena da prospettive e con deformazioni ottiche distinte, è fondamentale costruire un modello matematico che leghi rigidamente i due sistemi di riferimento. Questo processo avviene in due stadi sequenziali: la calibrazione intrinseca dei singoli sensori e la calibrazione estrinseca (stereo) del sistema complessivo.

\subsubsection{Calibrazione degli intrinseci}

Nessuna lente fisica è ideale; le ottiche introducono distorsioni radiali e tangenziali e il centro ottico reale (ovvero le coordinate in cui l'asse ottico interseca il piano immagine) non coincide quasi mai con il centro geometrico del sensore. Senza correggere queste anomalie, ogni tentativo di allineare le immagini risulterebbe impreciso, poiché la geometria interna della camera sarebbe falsata. Attraverso la calibrazione degli intrinseci, si ottengono i parametri interni alla camera che descrivono la trasformazione dai raggi di luce ai pixel digitali. Fanno parte di questa categoria la lunghezza focale, il punto principale (il centro ottico menzionato poc'anzi) e lo skew (parametro solitamente nullo nelle moderne camere). Questi parametri formano una matrice, nota come \emph{Camera Matrix}, che si basa sul modello \emph{pinhole} ideale. Per rappresentare in modo più accurato il comportamento reale di una lente, questo modello viene esteso con l'aggiunta dei coefficienti di distorsione, i quali correggono le deviazioni della proiezione ideale causate dalle imperfezioni ottiche. Tali coefficienti sono forniti come un vettore di parametri separato e non sono inseriti direttamente nella matrice intrinseca, in quanto modellano effetti non lineari.

La procedura di calibrazione intrinseca è stata implementata attraverso una pipeline basata sulla libreria OpenCV, finalizzata alla stima della matrice della camera e dei coefficienti di distorsione secondo il modello di Brown-Conrady. A partire da un dataset di immagini contenenti viste di una checkerboard, il processo inizia con il rilevamento degli angoli sulla scacchiera mediante il metodo \texttt{cv2.findChessboardCornersSB}, selezionato per la sua robustezza alle variazioni di luce, seguito da un raffinamento sub-pixel volto a mitigare l'errore di quantizzazione spaziale tramite \texttt{cv2.cornerSubPix}. Successivamente, viene impiegato il metodo di Zhang (\texttt{cv2.calibrateCamera}) per la risoluzione geometrica. Tale algoritmo sfrutta le omografie tra i punti del modello planare della scacchiera e le loro proiezioni immagine per vincolare e calcolare i parametri della camera. Il processo è stato inoltre arricchito da un meccanismo iterativo di filtraggio degli outlier: il sistema valuta ciclicamente l'errore di riproiezione di ogni frame, scartando progressivamente le acquisizioni meno coerenti fino al raggiungimento di una soglia prestabilita. Questo garantisce parametri intrinseci ottimizzati ed esenti da bias introdotti da frame di scarsa qualità. L'errore di riproiezione, utilizzato come metrica di qualità, è calcolato come la distanza euclidea media (in pixel) tra i punti rilevati nell'immagine e i corrispondenti punti 3D della scacchiera proiettati sul piano immagine utilizzando i parametri stimati.

\subsubsection{Calibrazione degli estrinseci}

Una volta linearizzata la geometria dei singoli sensori, è possibile procedere alla calibrazione stereo vera e propria. Questa fase ha lo scopo di determinare la relazione spaziale rigida tra la camera di riferimento (Mapir) e la seconda camera (RealSense). L'algoritmo calcola una matrice di rotazione (R) e un vettore di traslazione (t) che definiscono la trasformazione di coordinate necessaria per mappare il sistema di riferimento del primo sensore su quello del secondo. Il risultato finale di questa catena di calibrazioni è la rettifica epipolare, la quale garantisce che ogni riga di pixel delle due immagini sia perfettamente allineata sullo stesso piano orizzontale.

A seguito della calibrazione delle singole camere, è stata eseguita la calibrazione stereo (\texttt{cv2.stereoCalibrate}) estendendo il classico metodo di Zhang alla visione binoculare. A differenza della calibrazione a camera singola, dove ogni vista della checkerboard viene risolta come un evento indipendente, l'approccio stereo introduce un vincolo di rigidità geometrica all'interno del processo di ottimizzazione globale. Poiché i sensori sono fisicamente solidali, l'algoritmo impone che la relazione spaziale tra camera sinistra e destra rimanga invariata per tutte le coppie di immagini acquisite. Di conseguenza, il sistema viene risolto tramite un'ottimizzazione congiunta che minimizza simultaneamente la somma degli errori di riproiezione di entrambi i sensori, garantendo una maggiore robustezza. Una specifica scelta progettuale è stata l'applicazione del vincolo sulle caratteristiche intrinseche delle camere (tramite il flag \texttt{cv2.CALIB\_FIX\_INTRINSIC}); in tal modo, durante l'ottimizzazione, l'algoritmo ha utilizzato le matrici intrinseche già ottenute dalla calibrazione singola senza apportare ulteriori modifiche.

Anche in questa fase è stato implementato un sistema di rimozione degli outliers, costituiti ora da coppie di immagini, basato sull'analisi dell'errore epipolare, che funge da indicatore geometrico diretto della coerenza stereo. Per due camere disposte in un sistema stereo, la geometria epipolare stabilisce che un punto osservato in una vista della camera sinistra corrisponde ad una retta, definita linea epipolare, sulla vista della camera destra, lungo la quale deve necessariamente trovarsi il punto omologo.

Per ciascun punto, la distanza ortogonale tra il punto stesso e la sua linea epipolare costituisce l'errore epipolare. L'errore per ogni coppia di immagini viene calcolato come la radice quadrata della media dei quadrati di queste distanze ed è espresso in pixel. Vengono mantenute nel dataset soltanto le coppie che presentano un errore epipolare inferiore o uguale a una soglia prestabilita (1.0 px). Se l'operazione di filtraggio riduce il numero di campioni disponibili, viene eseguita una seconda calibrazione stereo utilizzando esclusivamente le coppie con errore al di sotto della soglia.

\subsubsection{Rettifica stereo}

La fase conclusiva del processo di calibrazione è la rettifica stereo (\texttt{cv2.stereoRectify}), procedura che utilizza una trasformazione matematica per rimappare i piani immagine originali su un nuovo piano comune in cui le linee epipolari risultano parallele e orizzontali. In termini pratici, ciò significa che ogni punto fisico osservato dalla camera sinistra viene proiettato sulla medesima riga di pixel nell'immagine della camera destra. Questo allineamento è il prerequisito indispensabile per semplificare il successivo problema di corrispondenza stereo, permettendo di passare da una ricerca bidimensionale a una più efficiente ricerca monodimensionale lungo l'asse orizzontale.

L'efficacia di questa trasformazione è strettamente dipendente dalla qualità della calibrazione iniziale. Nella Fig. \ref{fig:rectification-bad} è riportato un esempio di rettifica ottenuta utilizzando i parametri estrinseci stimati sull'intero dataset grezzo, senza una preventiva rimozione degli outlier. Si può chiaramente osservare come le linee epipolari non passino per i medesimi punti della scacchiera nelle due inquadrature, segnalando un errore sistematico nella geometria del sistema. 

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\textwidth]{ch-configurazione-sperimentale/images/rectified_comparison_0_bad.jpg}
	\caption{Rettifica stereo fallita: l'assenza di filtraggio degli outlier nei dati di calibrazione comporta un errato allineamento delle linee epipolari.}
	\label{fig:rectification-bad}
\end{figure}

Al contrario, la Fig. \ref{fig:rectification-good} mostra il risultato ottenuto applicando i parametri estrinseci calcolati dopo il filtraggio selettivo delle coppie di immagini. In questo caso, le linee epipolari risultano perfettamente coerenti tra le due viste, garantendo che ogni punto fisico si trovi sulla stessa riga di pixel in entrambi i sensori, condizione fondamentale per il successo della successiva fase di stereo matching.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=\textwidth]{ch-configurazione-sperimentale/images/rectified_comparison_16_good.jpg}
	\caption{Rettifica stereo corretta: il filtraggio del dataset di calibrazione permette di ottenere un allineamento epipolare ottimale.}
	\label{fig:rectification-good}
\end{figure}

\subsection{Stereo Matching}

A seguito della rettifica stereo, il sistema affronta la ricerca delle corrispondenze. L'obiettivo di questa fase è generare una mappatura densa che colleghi ogni pixel della camera di riferimento (Mapir - sinistra) al suo omologo nella camera secondaria (RealSense - destra). Questa operazione è propedeutica alla riproiezione dei punti: disponendo della mappa di disparità, diventa possibile trasferire l'informazione osservata dal sensore destro direttamente nel piano immagine del sensore sinistro, garantendo una sovrapposizione spaziale coerente tra i pixel provenienti dalle due camere. Come descritto nel paragrafo precedente, questa ricerca è ora vincolata alla sola dimensione orizzontale, fattore che semplifica notevolmente il costo computazionale.

\subsubsection{Pre-elaborazione e histogram matching}

Prima di procedere al matching geometrico, è stato necessario affrontare le differenze radiometriche tra i due sensori. Poiché la camera Mapir e la RealSense possiedono ottiche e sensori con curve di risposta spettrale differenti, le immagini acquisite presentavano distribuzioni di luminosità e contrasto non omogenee, pur inquadrando la stessa scena. Per mitigare questo disallineamento, è stato applicato un histogram matching tra la vista sinistra e la vista destra, entrambe convertite preliminarmente in scala di grigi. Questa operazione forza la distribuzione delle intensità dei pixel di una immagine ad adeguarsi a quella dell'altra, rendendo le due viste radiometricamente coerenti. L'implementazione di questa fase di pre-elaborazione ha comportato un miglioramento notevole nel calcolo della disparità, riducendo drasticamente gli errori di corrispondenza causati da differenze di esposizione che l'algoritmo avrebbe altrimenti interpretato come variazioni strutturali.

\subsubsection{Algoritmo di matching}

Per la generazione delle mappe di disparità è stato adottato l'algoritmo Semi-Global Block Matching (SGBM), implementato tramite la funzione \texttt{cv2.StereoSGBM}. A differenza dei metodi di block matching locali, che considerano solo la correlazione tra finestre di pixel, SGBM introduce un vincolo di regolarità globale che penalizza i cambiamenti bruschi di disparità, garantendo una ricostruzione più uniforme delle superfici.

\subsubsection{Strumento di tuning (Stereo-Tuner)}

Poiché i parametri ottimali di SGBM variano significativamente in base alle condizioni della scena, è stato sviluppato un tool dedicato, denominato Stereo-Tuner, basato su interfaccia grafica. Questo strumento permette di caricare coppie di immagini rettificate e radiometricamente allineate per manipolare in tempo reale i parametri dell'algoritmo. Tramite l'interfaccia, è possibile variare parametri critici come la dimensione della finestra di confronto (blockSize), l'intervallo di ricerca orizzontale (numDisparities) e la soglia di unicità (uniquenessRatio), osservando istantaneamente l'effetto sulla densità della mappa. Il tool permette inoltre di verificare visivamente la qualità della riproiezione per mezzo di una vista in blending, la quale consente di evidenziare disallineamenti residui tra la vista sinistra originale e la vista destra riproiettata.

L'output di questa fase è costituito dalle mappe di disparità per ciascuna coppia di immagini. Attraverso queste ultime, il sistema applica una trasformazione geometrica (warping) all'immagine della camera destra (RealSense), deformandola affinché si sovrapponga perfettamente alla geometria della camera sinistra (Mapir). Il risultato è un dataset di immagini perfettamente allineate, dove ogni coordinata (u, v) nel piano immagine della Mapir corrisponde alla stessa locazione fisica nel piano riproiettato della RealSense. Questo processo ha permesso di effettuare le successive analisi pixel-to-pixel, come il calcolo dell'NDVI.
